from typing import List, Dict, Optional, Any
from loguru import logger
import json

from app.schemas.page_sessions import PageSession, PageSegment
from app.schemas.tools import ToolsCatalog
from app.schemas.workflows import WorkflowSchema, WorkflowStepSchema
from app.services.utils import load_prompt
from openai import OpenAI
from app.core.config import settings


class GeneralizationService:
    """Service for generalizing workflows to make them reusable and not instance-bound"""

    def __init__(self):
        # Initialize OpenAI client
        self.client = OpenAI(api_key=settings.openai_api_key)
        self.llm_available = bool(settings.openai_api_key)

    async def generalize_workflow(
        self, page_segment: PageSegment, tools_catalog: ToolsCatalog
    ) -> Optional[WorkflowSchema]:
        """Main method to generalize a workflow from a multi-page segment using LLM analysis"""
        try:
            logger.info(f"Generalizing multi-page workflow for segment type: {page_segment.segment_type}")

            # Extract context from all pages in the segment
            page_content = self._extract_segment_content(page_segment)
            user_actions = self._extract_segment_actions(page_segment)

            # Use LLM to generate complete workflow
            workflow_data = await self._generate_workflow_with_llm(
                page_segment=page_segment,
                page_content=page_content,
                user_actions=user_actions,
                tools_catalog=tools_catalog,
            )

            if not workflow_data:
                logger.warning("No workflow generated by LLM")
                return None

            # Create workflow schema
            workflow = WorkflowSchema(
                id=None,  # Will be set when saving
                summary=workflow_data.get("summary", "Generated workflow"),
                steps=workflow_data.get("steps", []),
                domain=page_segment.domain,
                url_pattern=workflow_data.get("url_pattern"),
                confidence_score=0.0,
                is_active=True,
                execution_count=0,
                created_at=None,  # Will be set when saving
                updated_at=None,  # Will be set when saving
            )

            logger.info(f"Successfully generalized multi-page workflow: {workflow.summary}")
            return workflow

        except Exception as e:
            logger.error(f"Failed to generalize workflow from segment: {str(e)}")
            return None

    def _extract_segment_content(self, page_segment: PageSegment) -> str:
        """Extract content from all pages in the segment"""
        content_parts = []
        for i, page in enumerate(page_segment.pages, 1):
            # Truncate content to keep token usage manageable
            content = page.content_summary[:300] if len(page.content_summary) > 300 else page.content_summary
            content_parts.append(f"Page {i} ({page.title}): {content}")

        return "\n\n".join(content_parts)

    def _extract_segment_actions(self, page_segment: PageSegment) -> str:
        """Extract user actions from all pages in the segment"""
        actions = []
        for i, page in enumerate(page_segment.pages, 1):
            duration_sec = page.duration_ms // 1000
            actions.append(f"Page {i}: Spent {duration_sec}s on {page.title} ({page.event_count} events)")

        return "; ".join(actions)

    async def _generate_workflow_with_llm(
        self, page_segment: PageSegment, page_content: str, user_actions: str, tools_catalog: ToolsCatalog
    ) -> Optional[Dict[str, Any]]:
        """Generate complete workflow using LLM analysis from page segment"""

        if not self.llm_available:
            logger.warning("LLM not available - OpenAI API key not configured")
            return None

        try:
            llm_response = await self._call_llm_for_workflow(
                source=page_segment,
                page_content=page_content,
                user_actions=user_actions,
                tools_catalog=tools_catalog,
            )
            return await self._parse_llm_workflow_response(llm_response)
        except Exception as e:
            logger.error(f"Failed to generate workflow with LLM: {str(e)}")
            return None

    async def _call_llm_for_workflow(
        self, source, page_content: str, user_actions: str, tools_catalog: ToolsCatalog
    ) -> str:
        """Call LLM to generate complete workflow from page session or segment"""

        available_tools = []
        if tools_catalog and tools_catalog.tools:
            for tool in tools_catalog.tools:
                available_tools.append(tool.name)

        # Get segment type and domain from either PageSession or PageSegment
        segment_type = getattr(source, "segment_type", "unknown")
        domain = getattr(source, "domain", "")

        prompt = load_prompt(
            "workflow_generation.txt",
            variables={
                "segment_type": segment_type,
                "domain": domain,
                "page_content": page_content,
                "user_actions": user_actions,
                "available_tools": available_tools,
            },
        )

        try:
            response = self.client.chat.completions.create(
                model="gpt-5-mini-2025-08-07",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert at analyzing user workflows and creating reusable automation patterns.",
                    },
                    {"role": "user", "content": prompt},
                ],
            )

            return response.choices[0].message.content or ""

        except Exception as e:
            logger.error(f"OpenAI API call failed for workflow generation: {str(e)}")
            raise

    async def _parse_llm_workflow_response(self, llm_response: str) -> Optional[Dict[str, Any]]:
        """Parse LLM response into workflow data"""

        try:
            # Clean up the response - remove any markdown formatting
            cleaned_response = llm_response.strip()
            if cleaned_response.startswith("```json"):
                cleaned_response = cleaned_response[7:]
            if cleaned_response.endswith("```"):
                cleaned_response = cleaned_response[:-3]
            cleaned_response = cleaned_response.strip()

            # Parse JSON response
            workflow_data = json.loads(cleaned_response)

            # Convert steps to WorkflowStepSchema objects
            steps = []
            for step_data in workflow_data.get("steps", []):
                step = WorkflowStepSchema(
                    description=step_data.get("description", ""),
                    step_type=step_data.get("step_type", "browser_context"),
                    tools=step_data.get("tools", []),
                    tool_parameters=None,
                    context_selector=None,
                    context_description=step_data.get("context_description", ""),
                )
                steps.append(step)

            return {
                "summary": workflow_data.get("summary", ""),
                "steps": steps,
                "url_pattern": workflow_data.get("url_pattern", ""),
            }

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response: {str(e)}")
            logger.error(f"Response was: {llm_response}")
            return None
        except Exception as e:
            logger.error(f"Failed to parse LLM workflow response: {str(e)}")
            return None
